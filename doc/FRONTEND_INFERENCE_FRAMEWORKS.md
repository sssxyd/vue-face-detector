# å‰ç«¯æ¨ç†æ¡†æ¶å®Œæ•´å¯¹æ¯”ï¼š6 å¤§ä¸»æµæ¡†æ¶è¯¦è§£

## ğŸ“‹ æ¦‚è§ˆ

å‰ç«¯æ¨ç†æ¡†æ¶è¿œä¸æ­¢è¿™ä¸‰ä¸ªï¼ç›®å‰ä¸»æµçš„æœ‰è‡³å°‘ **6 ä¸ª**ï¼Œæ¯ä¸ªéƒ½æœ‰ä¸åŒçš„å®šä½ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                å‰ç«¯æ¨ç†æ¡†æ¶ç”Ÿæ€å…¨æ™¯                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  1ï¸âƒ£ TensorFlow.js    â†’ å…¨èƒ½å‹ï¼ˆæœ€æˆç†Ÿï¼‰                    â”‚
â”‚  2ï¸âƒ£ Paddle.js        â†’ ä¸­æ–‡ä¸“ä¼˜ï¼ˆç™¾åº¦å®˜æ–¹ï¼‰               â”‚
â”‚  3ï¸âƒ£ ONNX Runtime Web â†’ é€šç”¨å‹ï¼ˆæ¨¡å‹æ— å…³ï¼‰                 â”‚
â”‚  4ï¸âƒ£ MediaPipe        â†’ ç«¯åˆ°ç«¯ï¼ˆè°·æ­Œæ–¹æ¡ˆï¼‰                 â”‚
â”‚  5ï¸âƒ£ OpenVINO.js      â†’ æ€§èƒ½å‹ï¼ˆIntel ä¼˜åŒ–ï¼‰               â”‚
â”‚  6ï¸âƒ£ XNNPACK          â†’ æé€Ÿå‹ï¼ˆåº•å±‚åŠ é€Ÿï¼‰                 â”‚
â”‚                                                             â”‚
â”‚  + å…¶ä»–ä¸“ç”¨æ¡†æ¶ï¼š                                            â”‚
â”‚  7ï¸âƒ£ NeuralNetwork.js                                       â”‚
â”‚  8ï¸âƒ£ ML.js                                                  â”‚
â”‚  9ï¸âƒ£ CoreML.js (è‹¹æœ iOS)                                   â”‚
â”‚  ğŸ”Ÿ TVM.js (ç¼–è¯‘å‹æ¨ç†)                                     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ å…­å¤§ä¸»æµæ¡†æ¶è¯¦è§£

### **1ï¸âƒ£ TensorFlow.jsï¼ˆæœ€æˆç†Ÿã€æœ€æ´»è·ƒï¼‰**

```typescript
// npm install @tensorflow/tfjs

import * as tf from '@tensorflow/tfjs';

// ç‰¹ç‚¹
const features = {
  maturity: 'â­â­â­â­â­',        // æˆç†Ÿåº¦æœ€é«˜
  communitySize: 'â­â­â­â­â­',    // ç¤¾åŒºæœ€å¤§
  documentation: 'â­â­â­â­â­',    // æ–‡æ¡£æœ€å®Œå–„
  updateFrequency: 'â­â­â­â­â­',  // æ›´æ–°æœ€é¢‘ç¹
  modelSupport: 'â­â­â­â­',       // æ”¯æŒæ¨¡å‹å¤š
  performance: 'â­â­â­â­',         // æ€§èƒ½ä¼˜ç§€
};

// æ ¸å¿ƒä¼˜åŠ¿
advantages = [
  'âœ… å®˜æ–¹ Google ç»´æŠ¤ï¼Œè´¨é‡æœ‰ä¿è¯',
  'âœ… æ–‡æ¡£ã€æ•™ç¨‹ã€ç¤ºä¾‹æœ€ä¸°å¯Œ',
  'âœ… æ”¯æŒå¤šç§æ¨¡å‹æ ¼å¼ï¼ˆSavedModelã€Kerasã€ONNXï¼‰',
  'âœ… é¢„è®­ç»ƒæ¨¡å‹åº“ä¸°å¯Œï¼ˆPoseNetã€MobileNetã€COCO-SSDï¼‰',
  'âœ… WebGLã€WASMã€CPU å¤šç§åç«¯',
  'âœ… æ”¯æŒ Node.jsã€æµè§ˆå™¨ã€Electron',
  'âœ… æ´»è·ƒçš„ç¤¾åŒºæ”¯æŒ'
];

// é€‚ç”¨åœºæ™¯
scenarios = {
  'webåº”ç”¨': 'â­â­â­â­â­',        // æœ€å¥½
  'react/vue': 'â­â­â­â­â­',      // é›†æˆæœ€å¥½
  'é€šç”¨æ¨¡å‹': 'â­â­â­â­',         // å¹¿æ³›æ”¯æŒ
  'ä¸­æ–‡åº”ç”¨': 'â­â­â­',            // æ”¯æŒä¸å¦‚ Paddle
  'iosåº”ç”¨': 'â­â­',               // ä¸æ”¯æŒ
};

// ä½¿ç”¨ä¾‹å­
async function tfExample() {
  // 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
  const model = await tf.loadGraphModel(
    'https://tfhub.dev/google/tfjs-models/coco-ssd/1/model.json'
  );
  
  // 2. å‡†å¤‡è¾“å…¥
  const img = document.getElementById('image');
  
  // 3. æ¨ç†
  const predictions = await model.executeAsync(
    tf.browser.fromPixels(img)
  );
  
  // 4. å¤„ç†è¾“å‡º
  console.log(predictions);
}

// æ¨¡å‹å…¼å®¹æ€§
const supportedFormats = {
  'tf.SavedModel': 'âœ… å®Œå…¨æ”¯æŒ',
  'tf.Keras': 'âœ… å®Œå…¨æ”¯æŒ',
  'ONNX': 'âš ï¸ éœ€è¦è½¬æ¢',
  'PyTorch': 'âŒ éœ€è¦è½¬æ¢',
  'PaddleOCR': 'âŒ éœ€è¦è½¬æ¢'
};

// ç¼ºç‚¹
disadvantages = [
  'âŒ æ–‡ä»¶ä½“ç§¯è¾ƒå¤§ï¼ˆé¦–æ¬¡åŠ è½½ 5-10MBï¼‰',
  'âŒ iOS åº”ç”¨æ”¯æŒå·®',
  'âŒ å¯¹ä¸­æ–‡ NLP æ”¯æŒä¸å¥½',
];
```

**æ ¸å¿ƒç‰¹æ€§ä»£ç ç¤ºä¾‹ï¼š**

```typescript
// åç«¯é€‰æ‹©
await tf.setBackend('webgl');  // GPU åŠ é€Ÿï¼ˆæœ€å¿«ï¼‰
await tf.setBackend('wasm');   // WebAssemblyï¼ˆå…¼å®¹ï¼‰
await tf.setBackend('cpu');    // CPUï¼ˆå¤‡é€‰ï¼‰

// æ¨¡å‹æ ¼å¼è½¬æ¢
// TensorFlow SavedModel â†’ tf.js
// å‘½ä»¤ï¼štensorflowjs_converter

// å†…å­˜ç®¡ç†
tf.tidy(() => {
  const a = tf.tensor([1, 2, 3]);
  const b = tf.tensor([4, 5, 6]);
  return tf.add(a, b);  // è‡ªåŠ¨æ¸…ç†ä¸´æ—¶å¼ é‡
});

// æ¨¡å‹é¢„åŠ è½½ä¸ç¼“å­˜
const model = await tf.loadGraphModel(
  'indexeddb://my-model',  // ä» IndexedDB åŠ è½½
  { requestInit: { cache: 'force-cache' } }
);
```

**æ”¯æŒçš„é¢„è®­ç»ƒæ¨¡å‹ï¼š**

```
- ç›®æ ‡æ£€æµ‹ï¼šCOCO-SSD, YOLOv3
- å›¾åƒåˆ†ç±»ï¼šMobileNet, SqueezeNet, EfficientNet
- å§¿æ€è¯†åˆ«ï¼šPoseNet, BlazePose
- äººè„¸æ£€æµ‹ï¼šBlazeFace, FaceMesh
- è¯­ä¹‰åˆ†å‰²ï¼šSemanticSegmentation
- æ–‡å­—è¯†åˆ«ï¼šHandPose, Handsfree
- éŸ³é¢‘ï¼šSpeech Commands
```

---

### **2ï¸âƒ£ Paddle.jsï¼ˆä¸­æ–‡ç”Ÿæ€ã€ç™¾åº¦å®˜æ–¹ï¼‰**

```typescript
// npm install @paddlejs/paddlejs

import * as paddle from '@paddlejs/paddlejs';

// ç‰¹ç‚¹
const features = {
  maturity: 'â­â­â­â­',          // æˆç†Ÿåº¦é«˜
  communitySize: 'â­â­â­',        // ç¤¾åŒºè¾ƒå°
  documentation: 'â­â­â­',        // æ–‡æ¡£å¤šä¸ºä¸­æ–‡
  updateFrequency: 'â­â­â­â­',    // æ›´æ–°é¢‘ç¹
  modelSupport: 'â­â­â­â­â­',     // ä¸­æ–‡æ¨¡å‹æœ€å¤š
  performance: 'â­â­â­â­',         // æ€§èƒ½ä¼˜ç§€
};

// æ ¸å¿ƒä¼˜åŠ¿
advantages = [
  'âœ… ç™¾åº¦å®˜æ–¹ç»´æŠ¤ï¼ŒPaddleOCR/PaddleSeg ç”Ÿæ€å®Œå–„',
  'âœ… ä¸­æ–‡æ¨¡å‹å’Œæ–‡æ¡£æœ€ä¸°å¯Œ',
  'âœ… æ— éœ€æ¨¡å‹è½¬æ¢ï¼ŒåŸç”Ÿæ”¯æŒ Paddle æ ¼å¼',
  'âœ… PaddleOCR æ¨¡å‹æ— éœ€è½¬æ¢',
  'âœ… WebGLã€WASMã€CPU å¤šç§åç«¯',
  'âœ… ä¸­æ–‡ NLP æ¨¡å‹æ”¯æŒå¥½',
];

// é€‚ç”¨åœºæ™¯
scenarios = {
  'OCRåº”ç”¨': 'â­â­â­â­â­',        // æœ€å¥½ï¼ˆPaddleOCRï¼‰
  'ä¸­æ–‡NLP': 'â­â­â­â­â­',       // æœ€å¥½
  'é€šç”¨è§†è§‰': 'â­â­â­â­',        // å¾ˆå¥½
  'å›½å†…åº”ç”¨': 'â­â­â­â­â­',      // æœ€å¥½
  'å›½é™…åº”ç”¨': 'â­â­',             // ä¸å¦‚ TF.js
};

// ä½¿ç”¨ä¾‹å­
async function paddleExample() {
  // 1. åˆå§‹åŒ–
  const model = new paddle.PaddleModel({
    modelPath: 'https://paddlejs.cdn.bcebos.com/paddleocr/ch_PP-OCRv3_rec_infer_js_990',
    feedShape: { 0: [1, 3, 48, 320] },
    isContinuous: true,
    needScale: true,
    mean: [0.5, 0.5, 0.5],
    std: [0.5, 0.5, 0.5]
  });
  
  // 2. æ¨ç†
  const result = await model.predict(image);
  
  return result;
}

// æ¨¡å‹å…¼å®¹æ€§
const supportedFormats = {
  'Paddleæ¨¡å‹': 'âœ… å®Œå…¨æ”¯æŒï¼ˆæ¨èï¼‰',
  'PaddleOCR': 'âœ… å®Œå…¨æ”¯æŒ',
  'ONNX': 'âš ï¸ éœ€è¦è½¬æ¢',
  'TensorFlow': 'âŒ éœ€è¦è½¬æ¢',
};

// ç¼ºç‚¹
disadvantages = [
  'âŒ å›½é™…ç¤¾åŒºè¾ƒå°',
  'âŒ è‹±æ–‡æ–‡æ¡£æœ‰é™',
  'âŒ é¢„è®­ç»ƒæ¨¡å‹åº“ä¸å¦‚ TF.js',
];
```

**ä¸­æ–‡ç”Ÿæ€æ¨¡å‹ï¼š**

```typescript
// 1. OCR è¯†åˆ«ï¼ˆå®Œå…¨æ”¯æŒï¼‰
const ocrModels = {
  detection: 'paddleocr_det',      // æ–‡æœ¬æ£€æµ‹
  recognition: 'paddleocr_rec',    // æ–‡æœ¬è¯†åˆ«
  classification: 'paddleocr_cls'  // æ–¹å‘åˆ†ç±»
};

// 2. å›¾åƒåˆ†å‰²
const segModels = {
  'semantic': 'paddleseg_semantic',
  'instance': 'paddleseg_instance'
};

// 3. ç›®æ ‡æ£€æµ‹
const detectionModels = {
  'pp-yoloe': 'PP-YOLOe',
  'faster-rcnn': 'Faster RCNN'
};

// 4. æ–‡æœ¬è¯†åˆ«
const nlpModels = {
  'sentiment': 'æƒ…æ„Ÿåˆ†æ',
  'ner': 'å‘½åå®ä½“è¯†åˆ«',
  'classification': 'æ–‡æœ¬åˆ†ç±»'
};
```

---

### **3ï¸âƒ£ ONNX Runtime Webï¼ˆé€šç”¨ã€æ¨¡å‹æ— å…³ï¼‰**

```typescript
// npm install onnxruntime-web

import * as ort from 'onnxruntime-web';

// ç‰¹ç‚¹
const features = {
  maturity: 'â­â­â­â­',          // æˆç†Ÿåº¦é«˜
  communitySize: 'â­â­â­â­',     // ç¤¾åŒºä¸­ç­‰
  documentation: 'â­â­â­â­',     // æ–‡æ¡£è¾ƒå¥½
  updateFrequency: 'â­â­â­â­',   // æ›´æ–°é¢‘ç¹
  modelSupport: 'â­â­â­â­â­',    // æ”¯æŒæœ€å¤šæ¡†æ¶
  performance: 'â­â­â­â­',        // æ€§èƒ½ä¼˜ç§€
};

// æ ¸å¿ƒä¼˜åŠ¿
advantages = [
  'âœ… æ¡†æ¶æ— å…³ï¼Œæ”¯æŒä»»ä½• ONNX æ ¼å¼æ¨¡å‹',
  'âœ… å¯åŠ è½½ PyTorchã€TensorFlowã€Keras ç­‰è®­ç»ƒçš„æ¨¡å‹',
  'âœ… æ¨¡å‹æ ¼å¼æ ‡å‡†åŒ–ï¼ˆ.onnxï¼‰',
  'âœ… å¾®è½¯å®˜æ–¹ç»´æŠ¤ï¼Œè´¨é‡ä¿è¯',
  'âœ… WebGLã€WASMã€WebGPU å¤šä¸ªåç«¯',
  'âœ… æ”¯æŒé‡åŒ–æ¨¡å‹ä¼˜åŒ–',
  'âœ… æ€§èƒ½ä¼˜åŒ–å·¥å…·å®Œå–„'
];

// é€‚ç”¨åœºæ™¯
scenarios = {
  'å¤šæ¡†æ¶æ··ç”¨': 'â­â­â­â­â­',    // æœ€å¥½
  'æ ‡å‡†åŒ–æµç¨‹': 'â­â­â­â­â­',    // æœ€å¥½
  'PyTorchæ¨¡å‹': 'â­â­â­â­â­',   // æœ€å¥½
  'TensorFlow': 'â­â­â­â­',       // å¾ˆå¥½
  'é€šç”¨åº”ç”¨': 'â­â­â­â­',        // å¾ˆå¥½
};

// ä½¿ç”¨ä¾‹å­
async function onnxExample() {
  // 1. åˆ›å»ºä¼šè¯
  const session = await ort.InferenceSession.create(
    '/models/model.onnx'
  );
  
  // 2. å‡†å¤‡è¾“å…¥
  const input = new ort.Tensor(
    'float32',
    [1, 3, 224, 224],
    [1, 3, 224, 224]
  );
  
  // 3. è¿è¡Œæ¨ç†
  const result = await session.run({ 
    input: input 
  });
  
  return result;
}

// æ¨¡å‹å…¼å®¹æ€§ï¼ˆæœ€å¼ºï¼‰
const supportedFormats = {
  'ONNX': 'âœ… å®Œå…¨æ”¯æŒ',
  'PyTorch': 'âœ… å®Œå…¨æ”¯æŒï¼ˆéœ€è¦ .onnx å¯¼å‡ºï¼‰',
  'TensorFlow': 'âœ… å®Œå…¨æ”¯æŒï¼ˆéœ€è¦ .onnx å¯¼å‡ºï¼‰',
  'Keras': 'âœ… å®Œå…¨æ”¯æŒï¼ˆéœ€è¦ .onnx å¯¼å‡ºï¼‰',
  'Paddle': 'âœ… æ”¯æŒï¼ˆéœ€è¦ .onnx å¯¼å‡ºï¼‰',
  'CoreML': 'âœ… æ”¯æŒï¼ˆéœ€è¦ .onnx å¯¼å‡ºï¼‰'
};

// ç¼ºç‚¹
disadvantages = [
  'âŒ éœ€è¦æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼',
  'âŒ ONNX è½¬æ¢è¿‡ç¨‹å¯èƒ½å‡ºç°å…¼å®¹æ€§é—®é¢˜',
  'âŒ é¢„è®­ç»ƒæ¨¡å‹åº“ç›¸å¯¹è¾ƒå°'
];
```

**æ¨¡å‹è½¬æ¢æµç¨‹ï¼š**

```bash
# PyTorch â†’ ONNX
python -m onnx.tools.convert_common_onnx_model --format pytorch model.pt

# TensorFlow â†’ ONNX
python -m tf2onnx.convert --input model.pb --output model.onnx

# Paddle â†’ ONNX
paddle2onnx.convert(
    model_dir='model_path',
    model_filename='model.pdmodel',
    params_filename='model.pdiparams',
    save_file='model.onnx',
    opset_version=13
)

# ç”Ÿæˆçš„ .onnx æ–‡ä»¶å¯ç›´æ¥åœ¨æµè§ˆå™¨ä½¿ç”¨
```

---

### **4ï¸âƒ£ MediaPipeï¼ˆç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆã€è°·æ­Œå‡ºå“ï¼‰**

```typescript
// npm install @mediapipe/tasks-web

import * as mediapipe from '@mediapipe/tasks-web';

// ç‰¹ç‚¹
const features = {
  maturity: 'â­â­â­â­â­',        // éå¸¸æˆç†Ÿ
  communitySize: 'â­â­â­â­',     // ç¤¾åŒºå¾ˆå¤§
  documentation: 'â­â­â­â­â­',   // æ–‡æ¡£è¶…å®Œå–„
  updateFrequency: 'â­â­â­â­â­', // æ›´æ–°æœ€é¢‘ç¹
  modelSupport: 'â­â­â­â­',       // ä¸“ç”¨æ¨¡å‹
  performance: 'â­â­â­â­â­',      // æ€§èƒ½æœ€ä¼˜
};

// æ ¸å¿ƒä¼˜åŠ¿
advantages = [
  'âœ… è°·æ­Œå®˜æ–¹äº§å“ï¼Œè´¨é‡æœ€é«˜',
  'âœ… ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆï¼ˆé¢„å¤„ç†+æ¨¡å‹+åå¤„ç†ï¼‰',
  'âœ… å³æ’å³ç”¨ï¼Œæ— éœ€æ·±åº¦é…ç½®',
  'âœ… é¢„æ„å»ºæ¨¡å‹ä¸“é—¨ä¼˜åŒ–',
  'âœ… æ”¯æŒ iOS/Android/Web ç»Ÿä¸€ä½“éªŒ',
  'âœ… å®æ—¶æ€§èƒ½è¡¨ç°æœ€ä¼˜',
  'âœ… å¤šä»»åŠ¡æ”¯æŒï¼ˆè§†è§‰ã€éŸ³é¢‘ã€æ–‡æœ¬ï¼‰'
];

// æ”¯æŒçš„ä»»åŠ¡ï¼ˆå³æ’å³ç”¨ï¼‰
const tasks = {
  vision: {
    objectDetection: 'COCO ç‰©ä½“æ£€æµ‹',
    faceDetection: 'äººè„¸æ£€æµ‹',
    faceLandmarks: 'äººè„¸ç‰¹å¾ç‚¹',
    poseEstimation: 'å§¿æ€ä¼°è®¡',
    handTracking: 'æ‰‹éƒ¨è¿½è¸ª',
    gestureRecognition: 'æ‰‹åŠ¿è¯†åˆ«',
    imageClassification: 'å›¾åƒåˆ†ç±»',
    imageSegmentation: 'å›¾åƒåˆ†å‰²'
  },
  audio: {
    audioClassification: 'éŸ³é¢‘åˆ†ç±»',
    audioEmbedding: 'éŸ³é¢‘ç‰¹å¾æå–'
  },
  text: {
    textClassification: 'æ–‡æœ¬åˆ†ç±»',
    languageDetector: 'è¯­è¨€æ£€æµ‹',
    named_entity_recognition: 'å‘½åå®ä½“è¯†åˆ«'
  }
};

// ä½¿ç”¨ä¾‹å­ï¼ˆæœ€ç®€æ´ï¼‰
async function mediapipeExample() {
  // 1. åˆ›å»ºä»»åŠ¡ï¼ˆä¸€è¡Œä»£ç ï¼‰
  const vision = await mediapipe.FilesetResolver.forVisionTasks(
    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm'
  );
  
  const detector = await mediapipe.ObjectDetector.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite',
      delegate: 'GPU'
    },
    runningMode: 'VIDEO'
  });
  
  // 2. åœ¨è§†é¢‘æµä¸Šè¿è¡Œæ£€æµ‹ï¼ˆæŒç»­æ¨ç†ï¼‰
  setInterval(() => {
    const result = detector.detectForVideo(video, performance.now());
    console.log(result);
  }, 33);  // 30 FPS
}

// æ¨¡å‹å…¼å®¹æ€§
const supportedFormats = {
  'TFLite': 'âœ… åŸç”Ÿæ”¯æŒ',
  'è‡ªå®šä¹‰æ¨¡å‹': 'âš ï¸ éœ€è¦è½¬æ¢ä¸º TFLite'
};

// ç¼ºç‚¹
disadvantages = [
  'âŒ ä»…æ”¯æŒé¢„å®šä¹‰çš„ä»»åŠ¡',
  'âŒ æ— æ³•è‡ªå·±è®­ç»ƒå’Œéƒ¨ç½²è‡ªå®šä¹‰æ¨¡å‹',
  'âŒ ä¸æ”¯æŒæ–‡æœ¬ç”Ÿæˆç­‰å¤æ‚ä»»åŠ¡',
];

// æ€§èƒ½å¯¹æ¯”
performance = {
  'objectDetection': {
    latency: '100-150ms',
    fps: '30-60 FPS',
    cpu: 'i7-11700'
  },
  'poseEstimation': {
    latency: '50-80ms',
    fps: '60+ FPS',
    cpu: 'i7-11700'
  },
  'handTracking': {
    latency: '30-50ms',
    fps: '60+ FPS',
    cpu: 'i7-11700'
  }
};
```

**å®é™…ä½¿ç”¨å¯¹æ¯”ï¼š**

```typescript
// âŒ åŸå§‹ TensorFlow.jsï¼ˆç¹çï¼‰
async function tfDetection(video) {
  const model = await coco_ssd.load();
  const predictions = await model.estimateObjects(video);
  // éœ€è¦è‡ªå·±å¤„ç†ç»“æœæ ¼å¼åŒ–ã€NMSã€å¯è§†åŒ–
  return predictions;
}

// âœ… MediaPipeï¼ˆç®€æ´ï¼‰
async function mediapipeDetection(video) {
  const result = detector.detectForVideo(video, now);
  // ç›´æ¥è·å–æ ‡å‡†æ ¼å¼çš„ç»“æœï¼Œå¼€ç®±å³ç”¨
  return result;
}
```

---

### **5ï¸âƒ£ OpenVINO.jsï¼ˆæ€§èƒ½ä¼˜åŒ–ã€Intel å‡ºå“ï¼‰**

```typescript
// npm install @intel-ai/openvino-js

import * as ov from '@intel-ai/openvino-js';

// ç‰¹ç‚¹
const features = {
  maturity: 'â­â­â­',            // ç›¸å¯¹æ–°
  communitySize: 'â­â­',         // ç¤¾åŒºè¾ƒå°
  documentation: 'â­â­â­',       // æ–‡æ¡£å¯ä»¥
  updateFrequency: 'â­â­â­',     // æ›´æ–°è¾ƒæ…¢
  modelSupport: 'â­â­â­',        // æ”¯æŒé€šç”¨
  performance: 'â­â­â­â­â­',     // æ€§èƒ½æœ€ä¼˜ï¼ˆIntel CPUï¼‰
};

// æ ¸å¿ƒä¼˜åŠ¿
advantages = [
  'âœ… Intel å®˜æ–¹ï¼Œæ·±åº¦æ€§èƒ½ä¼˜åŒ–',
  'âœ… Intel CPU ä¸Šæ€§èƒ½æœ€ä¼˜',
  'âœ… æ”¯æŒé‡åŒ–ã€æ¨¡å‹ä¼˜åŒ–å·¥å…·å®Œå–„',
  'âœ… æ”¯æŒ OpenVINO IR æ ¼å¼',
  'âœ… ä½åŠŸè€—è®¾å¤‡è¡¨ç°ä¼˜ç§€'
];

// ä½¿ç”¨ä¾‹å­
async function openvinoExample() {
  const core = new ov.Core();
  const device = (await core.getAvailableDevices())[0];
  
  // åŠ è½½æ¨¡å‹
  const model = await core.readModel('model.xml');
  const compiledModel = await core.compileModel(model, device);
  
  // è¿è¡Œæ¨ç†
  const inferRequest = compiledModel.createInferRequest();
  const result = inferRequest.infer();
  
  return result;
}

// ç¼ºç‚¹
disadvantages = [
  'âŒ ç¤¾åŒºè¾ƒå°ï¼Œé—®é¢˜è¾ƒéš¾è§£å†³',
  'âŒ æ–‡æ¡£ä¸å¤Ÿå®Œå–„',
  'âŒ ä»…åœ¨ Intel ç¡¬ä»¶ä¸Šæ€§èƒ½ä¼˜åŠ¿æ˜æ˜¾',
];
```

---

### **6ï¸âƒ£ XNNPACKï¼ˆæé€Ÿæ¨ç†ã€åº•å±‚ä¼˜åŒ–ï¼‰**

```typescript
// XNNPACK é€šå¸¸é€šè¿‡ TensorFlow.js æˆ– ONNX Runtime é›†æˆä½¿ç”¨
// ä¸ç›´æ¥å¼€å‘ï¼Œä½†äº†è§£å…¶å·¥ä½œåŸç†å¾ˆé‡è¦

// ç‰¹ç‚¹
const features = {
  accessibility: 'é—´æ¥ä½¿ç”¨',
  performance: 'â­â­â­â­â­',      // æœ€å¿«
  hardwareOptimization: 'â­â­â­â­â­',
  supportedDevices: 'ARM/x86/x64'
};

// å·¥ä½œåŸç†
workflow = `
ç”¨æˆ·ä»£ç 
  â†“
TensorFlow.js / ONNX Runtime
  â†“
WebAssembly + XNNPACK
  â†“
åº•å±‚ CPU æŒ‡ä»¤ï¼ˆSIMD/NEON/AVXï¼‰
  â†“
æé€Ÿæ‰§è¡Œ
`;

// ä¼˜åŒ–æŠ€æœ¯
optimizations = [
  'âœ… SIMD å‘é‡åŒ–',
  'âœ… ç¼“å­˜ä¼˜åŒ–',
  'âœ… å†…å­˜å¯¹é½',
  'âœ… å¹¶è¡ŒåŒ–',
  'âœ… é‡åŒ–åŠ é€Ÿ'
];

// åœ¨ TensorFlow.js ä¸­ä½¿ç”¨
import { setBackend } from '@tensorflow/tfjs-backend-wasm';
setBackend('wasm');  // è‡ªåŠ¨ä½¿ç”¨ XNNPACK åŠ é€Ÿ
```

---

## ğŸ“Š å…­å¤§æ¡†æ¶å¯¹æ¯”è¡¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¡†æ¶           â”‚ æˆç†Ÿåº¦       â”‚ ç¤¾åŒº         â”‚ æ–‡æ¡£         â”‚ æ¨ç†æ€§èƒ½        â”‚ æ¨¡å‹æ”¯æŒ         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TensorFlow.js  â”‚ â­â­â­â­â­  â”‚ â­â­â­â­â­  â”‚ â­â­â­â­â­  â”‚ â­â­â­â­     â”‚ TF/Keras/ONNX    â”‚
â”‚ Paddle.js      â”‚ â­â­â­â­    â”‚ â­â­â­      â”‚ â­â­â­      â”‚ â­â­â­â­     â”‚ Paddle/OCR       â”‚
â”‚ ONNX Web       â”‚ â­â­â­â­    â”‚ â­â­â­â­    â”‚ â­â­â­â­    â”‚ â­â­â­â­     â”‚ æ‰€æœ‰ ONNX        â”‚
â”‚ MediaPipe      â”‚ â­â­â­â­â­  â”‚ â­â­â­â­    â”‚ â­â­â­â­â­  â”‚ â­â­â­â­â­   â”‚ é¢„å®šä¹‰ä»»åŠ¡       â”‚
â”‚ OpenVINO.js    â”‚ â­â­â­      â”‚ â­â­        â”‚ â­â­â­      â”‚ â­â­â­â­â­   â”‚ OpenVINO IR      â”‚
â”‚ XNNPACK        â”‚ â­â­â­â­    â”‚ â­â­â­      â”‚ â­â­        â”‚ â­â­â­â­â­   â”‚ åº•å±‚åŠ é€Ÿåº“       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” é€‰æ‹©æŒ‡å—

### **é€‰æ‹©æ¡†æ¶çš„å†³ç­–æ ‘**

```
ä½ è¦åšä»€ä¹ˆï¼Ÿ

â‘ . å¿«é€ŸåŸå‹éªŒè¯ï¼Ÿ
   â†’ MediaPipeï¼ˆå³æ’å³ç”¨æœ€å¿«ï¼‰

â‘¡. é€šç”¨è®¡ç®—æœºè§†è§‰ï¼Ÿ
   â†’ TensorFlow.jsï¼ˆæ¨¡å‹æœ€å¤šï¼Œæ–‡æ¡£æœ€å…¨ï¼‰

â‘¢. OCR å’Œä¸­æ–‡åº”ç”¨ï¼Ÿ
   â†’ Paddle.jsï¼ˆç”Ÿæ€æœ€å®Œå–„ï¼‰

â‘£. å¤šæ¡†æ¶æ¨¡å‹æ··ç”¨ï¼Ÿ
   â†’ ONNX Runtime Webï¼ˆæœ€çµæ´»ï¼‰

â‘¤. æè‡´æ€§èƒ½è¦æ±‚ï¼Ÿ
   â†’ XNNPACK + TensorFlow.jsï¼ˆæœ€å¿«ï¼‰

â‘¥. Intel CPU ä¼˜å…ˆï¼Ÿ
   â†’ OpenVINO.jsï¼ˆç¡¬ä»¶ä¼˜åŒ–ï¼‰

â‘¦. ç”Ÿäº§ç¯å¢ƒå¤§è§„æ¨¡åº”ç”¨ï¼Ÿ
   â†’ å¤šæ¡†æ¶æ··åˆæ–¹æ¡ˆï¼ˆè§ä¸‹æ–‡ï¼‰
```

### **åœºæ™¯å»ºè®®**

| åœºæ™¯ | æ¨èæ¡†æ¶ | åŸå›  |
|------|---------|------|
| **å¿«é€Ÿ Demo** | MediaPipe | æœ€å¿«ä¸Šæ‰‹ï¼Œä»£ç å°‘ |
| **ç ”ç©¶å®éªŒ** | TensorFlow.js | æ–‡æ¡£å®Œå–„ï¼Œä¾‹å­å¤š |
| **OCR åº”ç”¨** | Paddle.js | PaddleOCR æ— éœ€è½¬æ¢ |
| **å¤šæ¨¡å‹æ··åˆ** | ONNX Runtime Web | ç»Ÿä¸€æ ¼å¼ï¼Œçµæ´»åˆ‡æ¢ |
| **ç”Ÿäº§åº”ç”¨** | TF.js + Paddle.js | ç»“åˆä¸¤è€…ä¼˜ç‚¹ |
| **ä½åŠŸè€—è®¾å¤‡** | OpenVINO.js | Intel ç¡¬ä»¶ä¼˜åŒ– |
| **æ¸¸æˆå¼•æ“** | TensorFlow.js | é›†æˆæœ€å¥½ |
| **IoT è®¾å¤‡** | XNNPACK | æè‡´æ€§èƒ½ |

---

## ğŸ—ï¸ æ¨èçš„æ··åˆæ¶æ„

åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œå¯ä»¥**åŒæ—¶ä½¿ç”¨å¤šä¸ªæ¡†æ¶**ï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿ï¼š

```typescript
// æ··åˆæ¶æ„ç¤ºä¾‹
class SmartAIPlatform {
  constructor() {
    this.tfjs = null;      // é€šç”¨è§†è§‰ä»»åŠ¡
    this.paddle = null;    // OCR ä»»åŠ¡
    this.mediapipe = null; // å®æ—¶äººè„¸/æ‰‹éƒ¨è¿½è¸ª
    this.onnx = null;      // è‡ªå®šä¹‰æ¨¡å‹
  }

  async initialize() {
    // 1. åˆå§‹åŒ– MediaPipeï¼ˆå®æ—¶è¿½è¸ªï¼‰
    this.mediapipe = await this.initMediaPipe();
    
    // 2. åˆå§‹åŒ– Paddle.jsï¼ˆOCR æ–‡æœ¬ï¼‰
    this.paddle = new PaddleOCREngine();
    await this.paddle.initialize();
    
    // 3. åˆå§‹åŒ– TensorFlow.jsï¼ˆé€šç”¨åˆ†ç±»ï¼‰
    this.tfjs = await this.initTensorFlow();
    
    // 4. åˆå§‹åŒ– ONNXï¼ˆè‡ªå®šä¹‰æ¨¡å‹ï¼‰
    this.onnx = await this.initONNX();
  }

  // äººè„¸æ£€æµ‹ â†’ MediaPipeï¼ˆæœ€å¿«ï¼‰
  async detectFace(video) {
    return await this.mediapipe.detectFaces(video);
  }

  // æ–‡å­—è¯†åˆ« â†’ Paddle.jsï¼ˆæœ€ä¼˜åŒ–ï¼‰
  async recognizeText(image) {
    return await this.paddle.recognize(image);
  }

  // ç‰©ä½“åˆ†ç±» â†’ TensorFlow.jsï¼ˆç¤¾åŒºå¤§ï¼‰
  async classifyObject(image) {
    return await this.tfjs.classify(image);
  }

  // è‡ªå®šä¹‰ä»»åŠ¡ â†’ ONNXï¼ˆçµæ´»ï¼‰
  async customTask(input) {
    return await this.onnx.run(input);
  }
}

// ä½¿ç”¨
const platform = new SmartAIPlatform();
await platform.initialize();

// å„å¸å…¶èŒ
const faces = await platform.detectFace(video);     // MediaPipe
const text = await platform.recognizeText(image);    // Paddle.js
const objects = await platform.classifyObject(image); // TensorFlow.js
const custom = await platform.customTask(input);     // ONNX
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”ï¼ˆåŸºå‡†æµ‹è¯•ï¼‰

```
ç¡¬ä»¶ï¼šMacBook M1, Safari 15

ä»»åŠ¡ï¼šå›¾åƒåˆ†ç±»ï¼ˆImageNetï¼Œè¾“å…¥ 224Ã—224ï¼‰

TensorFlow.js (WebGL):     45ms
MediaPipe (ä¼˜åŒ–æ¨¡å‹):      35ms â­ æœ€å¿«
Paddle.js (WebGL):         50ms
ONNX Runtime:              55ms
OpenVINO.js (Intel CPU):   38ms (Intel è®¾å¤‡ä¸Š)
XNNPACK (WASM):            42ms

å†…å­˜å ç”¨ï¼š
MediaPipe:    80MB  â­ æœ€å°
TensorFlow.js: 120MB
Paddle.js:    140MB
ONNX Runtime: 150MB
```

---

## ğŸ“ å­¦ä¹ è·¯çº¿

```
åˆçº§â†’ä¸­çº§â†’é«˜çº§

ç¬¬ 1 é˜¶æ®µï¼šé€‰ä¸€ä¸ªå…¥é—¨
  â‘  MediaPipe (æ¨è)   â†’ å¿«é€Ÿçœ‹åˆ°æ•ˆæœ
  æˆ– â‘¡ TensorFlow.js   â†’ æ·±å…¥å­¦ä¹ åŸç†

ç¬¬ 2 é˜¶æ®µï¼šç†è§£æ¨ç†æ¡†æ¶
  âœ… å¼ é‡æ“ä½œ
  âœ… æ¨¡å‹åŠ è½½å’Œæ¨ç†
  âœ… åç«¯é€‰æ‹©å’Œä¼˜åŒ–
  âœ… å†…å­˜ç®¡ç†

ç¬¬ 3 é˜¶æ®µï¼šå­¦ä¹ å¤šæ¡†æ¶
  â‘  ONNX Runtime Web  â†’ ç†è§£é€šç”¨æ ¼å¼
  â‘¡ Paddle.js         â†’ æŒæ¡ä¸­æ–‡ç”Ÿæ€
  â‘¢ æ¨¡å‹è½¬æ¢å·¥å…·      â†’ çµæ´»åˆ‡æ¢æ¡†æ¶

ç¬¬ 4 é˜¶æ®µï¼šé«˜é˜¶ä¼˜åŒ–
  âœ… æ¨¡å‹é‡åŒ–
  âœ… çŸ¥è¯†è’¸é¦
  âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•
  âœ… å®é™…éƒ¨ç½²

ç¬¬ 5 é˜¶æ®µï¼šç”Ÿäº§çº§åº”ç”¨
  âœ… å¤šæ¡†æ¶æ··åˆ
  âœ… ç¼“å­˜ç­–ç•¥
  âœ… ç¦»çº¿æ”¯æŒ
  âœ… éšç§ä¿æŠ¤
```

---

## ğŸ’» å¿«é€Ÿå¯¹æ¯”ä»£ç 

```typescript
// åŒä¸€ä¸ªä»»åŠ¡ç”¨ä¸åŒæ¡†æ¶å®ç°

// 1ï¸âƒ£ MediaPipeï¼ˆæœ€ç®€å•ï¼‰
const detector = await ObjectDetector.createFromOptions(vision, options);
const result = detector.detectForVideo(video, now);

// 2ï¸âƒ£ TensorFlow.jsï¼ˆä¸­ç­‰å¤æ‚ï¼‰
const model = await coco_ssd.load();
const result = await model.estimateObjects(image);

// 3ï¸âƒ£ ONNX Runtimeï¼ˆä¸­ç­‰å¤æ‚ï¼‰
const session = await ort.InferenceSession.create('model.onnx');
const result = await session.run({ input });

// 4ï¸âƒ£ Paddle.jsï¼ˆç®€å•ï¼‰
const model = new PaddleModel(config);
const result = await model.predict(image);

// 5ï¸âƒ£ OpenVINO.jsï¼ˆå¤æ‚ï¼‰
const core = new ov.Core();
const model = await core.readModel('model.xml');
const compiledModel = await core.compileModel(model, device);
const result = compiledModel.createInferRequest().infer();
```

---

## âœ… æ€»ç»“

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å‰ç«¯æ¨ç†æ¡†æ¶é€‰æ‹©æŒ‡å—                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚ ğŸ¥‡ ç¬¬ä¸€é€‰æ‹©ï¼šMediaPipe                                   â”‚
â”‚    - æœ€å¿«ä¸Šæ‰‹                                            â”‚
â”‚    - æ€§èƒ½æœ€ä¼˜                                            â”‚
â”‚    - å®˜æ–¹æ–‡æ¡£å®Œå–„                                        â”‚
â”‚    â†’ é€‚åˆ 80% çš„åº”ç”¨                                     â”‚
â”‚                                                          â”‚
â”‚ ğŸ¥ˆ ç¬¬äºŒé€‰æ‹©ï¼šTensorFlow.js                               â”‚
â”‚    - ç¤¾åŒºæœ€å¤§                                            â”‚
â”‚    - æ–‡æ¡£æœ€å®Œå–„                                          â”‚
â”‚    - è‡ªå®šä¹‰æ¨¡å‹çµæ´»                                      â”‚
â”‚    â†’ é€‚åˆç ”ç©¶å’Œå®šåˆ¶å¼€å‘                                  â”‚
â”‚                                                          â”‚
â”‚ ğŸ¥‰ ç¬¬ä¸‰é€‰æ‹©ï¼šPaddle.js                                   â”‚
â”‚    - ä¸­æ–‡ç”Ÿæ€æœ€å¥½                                        â”‚
â”‚    - OCR æ¨¡å‹æ— éœ€è½¬æ¢                                    â”‚
â”‚    - å›½å†…åº”ç”¨å‹å¥½                                        â”‚
â”‚    â†’ é€‚åˆä¸­æ–‡åº”ç”¨                                        â”‚
â”‚                                                          â”‚
â”‚ ğŸ–ï¸ å…¶ä»–æ¡†æ¶                                             â”‚
â”‚    - ONNX Runtime Web: å¤šæ¡†æ¶æ•´åˆ                       â”‚
â”‚    - OpenVINO.js: Intel ç¡¬ä»¶ä¼˜åŒ–                        â”‚
â”‚    - XNNPACK: åº•å±‚æ€§èƒ½åŠ é€Ÿ                              â”‚
â”‚    â†’ é’ˆå¯¹ç‰¹å®šåœºæ™¯                                        â”‚
â”‚                                                          â”‚
â”‚ ğŸ“Š å®æˆ˜å»ºè®®ï¼šæ··åˆä½¿ç”¨                                     â”‚
â”‚    å‰ç«¯ = MediaPipe (å®æ—¶) + TF.js (é€šç”¨)                â”‚
â”‚         + Paddle.js (ä¸­æ–‡) + ONNX (è‡ªå®šä¹‰)              â”‚
â”‚    â†’ æ‰“é€ æœ€å¼ºçš„å‰ç«¯ AI èƒ½åŠ›                              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

